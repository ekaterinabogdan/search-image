{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KSvc8w4n8VV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from PIL import Image as PILImage\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupShuffleSplit,train_test_split\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTkyBFDqC0ZL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvtlonE6C-IY"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/to_upload-2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVh03wxBLvN6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(f\"{BASE_DIR}/train_dataset.csv\")\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG4IUYymelrC"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mlp1FLFLzhy"
      },
      "outputs": [],
      "source": [
        "crowd_df = pd.read_csv(\n",
        "    f\"{BASE_DIR}/CrowdAnnotations.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None\n",
        ")\n",
        "\n",
        "crowd_df.columns = [\n",
        "    \"image_name\",\n",
        "    \"caption_id\",\n",
        "    \"agree_ratio\",\n",
        "    \"agree_count\",\n",
        "    \"disagree_count\"\n",
        "]\n",
        "\n",
        "crowd_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uae8l_pwepfE"
      },
      "outputs": [],
      "source": [
        "crowd_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnwCt2R_MGuX"
      },
      "outputs": [],
      "source": [
        "expert_df = pd.read_csv(\n",
        "    f\"{BASE_DIR}/ExpertAnnotations.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None\n",
        ")\n",
        "\n",
        "expert_df.columns = [\n",
        "    \"image_name\",\n",
        "    \"caption_id\",\n",
        "    \"expert_1\",\n",
        "    \"expert_2\",\n",
        "    \"expert_3\"\n",
        "]\n",
        "\n",
        "expert_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnZx59-tet3n"
      },
      "outputs": [],
      "source": [
        "expert_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcHi0N2VMNrO"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\n",
        "    f\"{BASE_DIR}/test_queries.csv\",\n",
        "    sep=\"|\"\n",
        ")\n",
        "\n",
        "test_df.head()\n",
        "\n",
        "\n",
        "\n",
        "  # При загрузке файла `test_queries.csv` возникла ошибка парсинга,для корректной загрузки данных разделитель был задан явно (`sep=\"|\"`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UHCy-1ueyBo"
      },
      "outputs": [],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjRsWihJg4C0"
      },
      "outputs": [],
      "source": [
        "test_df = test_df.drop(columns=[\"Unnamed: 0\"])\n",
        "test_df = test_df.rename(columns={\"image\": \"image_name\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULqRDrHRcjGY"
      },
      "outputs": [],
      "source": [
        "print(\"train:\", train_df.shape)\n",
        "print(\"crowd:\", crowd_df.shape)\n",
        "print(\"expert:\", expert_df.shape)\n",
        "print(\"test:\", test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMxsPoAik1N_"
      },
      "source": [
        "## Вывод:\n",
        "\n",
        "В ходе предварительной работы с датасетом мы проделали следующие шаги:\n",
        "\n",
        "1. **Загрузка данных:**  \n",
        "   Все необходимые файлы (`train_dataset.csv`, `CrowdAnnotations.tsv`, `ExpertAnnotations.tsv`, `test_queries.csv`) и папки с изображениями были успешно загружены из Google Drive в среду Colab.\n",
        "\n",
        "2. **Проверка структуры и типов данных:**  \n",
        "   - Таблицы `train_df`, `crowd_df` и `expert_df` имеют корректные размеры и типы данных, пропусков не выявлено.  \n",
        "   - Таблица `test_df` первоначально содержала некорректный разделитель и лишнюю колонку `Unnamed: 0`.\n",
        "\n",
        "3. **Корректировка данных:**  \n",
        "   - В `test_df` был явным образом указан разделитель (`sep=\"|\"`) для корректного считывания столбцов.  \n",
        "   - Удалена лишняя колонка `Unnamed: 0`.  \n",
        "   - Столбцы приведены к единому формату: `query_id`, `query_text`, `image_name`.\n",
        "\n",
        "4.На данном этапе датасет полностью подготовлен для следующего этапа PoC — фильтрации запрещённого контента, объединения разметки и формирования обучающей выборки для модели.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYIJJy-7m5OO"
      },
      "source": [
        "1  1. Исследовательский анализ данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP0qQwpOo-k6"
      },
      "source": [
        "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи мы должны эти оценки агрегировать — превратить в одну.\n",
        "\n",
        "Для каждой пары изображение–текст — 3 оценки экспертов\n",
        "\n",
        "Шкала от 1 до 4\n",
        "\n",
        "Нужно получить одну итоговую оценку\n",
        "\n",
        "В случае полного расхождения (1, 2, 4) — пару можно исключить\n",
        "\n",
        "Посмотрим распределение экспертных оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkcnVwAbmXs6"
      },
      "outputs": [],
      "source": [
        "expert_df[['expert_1', 'expert_2', 'expert_3']].stack().value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwwgUI7YqMu1"
      },
      "source": [
        "Эксперты чаще всего ставят низкие оценки (1–2)\n",
        "\n",
        "Полное соответствие (оценка 4) встречается реже всего."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAC47lNYpea5"
      },
      "outputs": [],
      "source": [
        "def aggregate_expert_votes(row):\n",
        "    votes = [row['expert_1'], row['expert_2'], row['expert_3']] # используем голосование большинства\n",
        "    counter = Counter(votes)\n",
        "\n",
        "    most_common = counter.most_common(1)[0]\n",
        "    if most_common[1] >= 2:\n",
        "        return most_common[0]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRtExWA7psUI"
      },
      "outputs": [],
      "source": [
        "expert_df['expert_score'] = expert_df.apply(aggregate_expert_votes, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgXNX4R5pxao"
      },
      "outputs": [],
      "source": [
        "expert_df['expert_score'].isna().value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvwKLEpVqUks"
      },
      "source": [
        "Всего пар: 5822\n",
        "\n",
        "Конфликтные оценки : 126\n",
        "\n",
        "Таким рбразом, доля конфликтов небольшая."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQol-4dWpztU"
      },
      "outputs": [],
      "source": [
        "expert_clean = expert_df.dropna(subset=['expert_score']).copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TKBozeJsaVr"
      },
      "source": [
        "Приведём экспертную оценку к [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2czOsOzsS9a"
      },
      "outputs": [],
      "source": [
        "expert_clean['expert_score_norm'] = (expert_clean['expert_score'] - 1) / 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj_yS2mkwK9r"
      },
      "source": [
        "Проведём анализ краудсорсинговых оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It98_agO1kNO"
      },
      "outputs": [],
      "source": [
        "expert_df[['expert_1', 'expert_2', 'expert_3']].stack().value_counts().sort_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu8G4mRa3ceD"
      },
      "source": [
        "Большинство пар изображение–текст либо:\n",
        "\n",
        "совсем не соответствуют друг другу,\n",
        "\n",
        "либо имеют лишь частичное совпадение\n",
        "\n",
        "Полное или почти полное соответствие (оценки 3–4) встречается существенно реже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb-lyf7u1vv_"
      },
      "outputs": [],
      "source": [
        "crowd_df['agree_ratio'].value_counts().sort_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-NeBKGw3kE9"
      },
      "source": [
        "В большинтсве случаев agree_ratio = 0\n",
        "\n",
        "Это означает, что ни один исполнитель не подтвердил соответствие\n",
        "\n",
        "Значения выше 0.5 встречаются редко. Крауд-разметка является очень строгой и подтверждает соответствие только в очевидных ситуациях."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zoypy4614Fu"
      },
      "outputs": [],
      "source": [
        "crowd_df['total_votes'] = (\n",
        "    crowd_df['agree_count'] + crowd_df['disagree_count']\n",
        ")\n",
        "\n",
        "crowd_df['total_votes'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrU8L9jH3umJ"
      },
      "source": [
        "В подавляющем большинстве случаев голосуют 3 человека\n",
        "\n",
        "Реже — 4–6 исполнителей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL5trXu721qd"
      },
      "outputs": [],
      "source": [
        "(crowd_df['agree_ratio'] > 0.5).value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOLs8Enr3yh3"
      },
      "source": [
        "94.3% пар считаются несоответствующими\n",
        "\n",
        "5.7% — соответствующими.\n",
        "\n",
        "Крауд-разметка сильно смещена в сторону отрицательного класса и не подходит как единственный источник целевой переменной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl9Y-M9N4h-v"
      },
      "source": [
        "Экспертная разметка — более надёжная.Крауд — более шумный, но массовый\n",
        "\n",
        "Поэтому используем объединение:\n",
        "\n",
        "эксперт: 0.6\n",
        "\n",
        "крауд: 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYIgJ2hbE8tn"
      },
      "outputs": [],
      "source": [
        "expert_ready = expert_clean[[\n",
        "    'image_name', 'caption_id', 'expert_score_norm'\n",
        "]]\n",
        "\n",
        "crowd_ready = crowd_df[[\n",
        "    'image_name', 'caption_id', 'agree_ratio'\n",
        "]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lm7DlioOudd"
      },
      "outputs": [],
      "source": [
        "merged_df = expert_ready.merge(\n",
        "    crowd_ready,\n",
        "    on=['image_name', 'caption_id'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "merged_df['agree_ratio'] = merged_df['agree_ratio'].fillna(0)\n",
        "\n",
        "\n",
        "merged_df['target'] = 0.6 * merged_df['expert_score_norm'] + 0.4 * merged_df['agree_ratio']\n",
        "\n",
        "\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX6OwSgQSfKA"
      },
      "source": [
        "Таким образом,  были изучены экспертные и краудсорсинговые оценки соответствия текста и изображения. Анализ показал, что датасет  несбалансирован: большинство пар изображение–текст не являются релевантными, что подтверждается как экспертной, так и крауд-разметкой.\n",
        "\n",
        "Экспертные оценки обладают большей информативностью и позволяют различать степень соответствия, тогда как краудсорсинговые оценки носят более строгий и бинарный характер и могут использоваться как дополнительный сигнал уверенности.\n",
        "\n",
        "На основе агрегированной экспертной оценки и доли согласия крауда была сформирована целевая переменная в диапазоне от 0 до 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCDIM9yRbf0R"
      },
      "source": [
        "**Проверка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn-naLjwetFV"
      },
      "source": [
        "Согласно законодательству ряда стран, запрещено предоставлять доступ к контенту, содержащему изображения или описания детей младше 16 лет, без согласия законных представителей.\n",
        "\n",
        "Так как в рамках PoC отсутствует механизм показа дисклеймера, все такие изображения должны быть исключены из обучающей выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZTkBiccjTlq"
      },
      "outputs": [],
      "source": [
        "full_df = merged_df.merge(\n",
        "    train_df,\n",
        "    left_on='caption_id',\n",
        "    right_on='query_id',\n",
        "    how='left'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NN3XpbtevI_"
      },
      "outputs": [],
      "source": [
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbhx6Fo3gE6h"
      },
      "outputs": [],
      "source": [
        "BLOCK_LEMMAS = {\n",
        "    \"child\", \"kid\", \"boy\", \"girl\",\n",
        "    \"baby\", \"toddler\", \"infant\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDjfbuO0gIcP"
      },
      "outputs": [],
      "source": [
        "def contains_blocked_content(text):\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text).lower()\n",
        "    doc = nlp(text)\n",
        "\n",
        "    return any(token.lemma_ in BLOCK_LEMMAS for token in doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7blB01H-jcAH"
      },
      "outputs": [],
      "source": [
        "full_df[\"has_children\"] = full_df[\"query_text\"].apply(contains_blocked_content)\n",
        "clean_df = full_df[~full_df[\"has_children\"]].copy()\n",
        "clean_df.drop(columns=[\"has_children\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpB-1hsemmoL"
      },
      "outputs": [],
      "source": [
        "full_df['has_children'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "219v3Gptmp6E"
      },
      "outputs": [],
      "source": [
        "full_df[full_df['has_children']].head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u1t80YrnJqJ"
      },
      "outputs": [],
      "source": [
        "IMAGES_DIR = \"/content/drive/MyDrive/Colab Notebooks/to_upload-2/train_images\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpKegHaxnMJn"
      },
      "outputs": [],
      "source": [
        "blocked_samples = full_df[full_df['has_children']]['image_name'].unique()[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXDrebNBnP8k"
      },
      "outputs": [],
      "source": [
        "for img_name in blocked_samples:\n",
        "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
        "    display(Image(filename=img_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmOE3EjQoM0Y"
      },
      "source": [
        "Фильтрация выполнена по текстовым описаниям, что может приводить к блокировке изображений без детей, если текст содержит запрещённые слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP0ENb5Xn-fp"
      },
      "source": [
        "Таким образом, на банном этапе выполнена проверка текстов на наличие запрещённых слов, указывающих на детей.\n",
        "\n",
        "Тексты были лемматизированы с использованием spaCy, приведены к нижнему регистру и очищены от лишних символов.\n",
        "\n",
        "Все строки с детьми были помечены и удалены из обучающего датасета."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Векторизация текстов**\n",
        "\n",
        "Для векторизации текстовых описаний используем предобученную модель BERT."
      ],
      "metadata": {
        "id": "asfEZIATLaOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "id": "fJPeECfkN7n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "bert_model = bert_model.to(device)\n",
        "bert_model.eval()\n"
      ],
      "metadata": {
        "id": "xBw1DvQaOkhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_vector(text, max_length=64):\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "\n",
        "    vector = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    return vector.squeeze().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "WMmcd0GWOvvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectors = {}\n",
        "\n",
        "for caption_id, text in tqdm(\n",
        "    clean_df[['caption_id', 'query_text']].drop_duplicates().values\n",
        "):\n",
        "    vec = text_to_vector(text)\n",
        "    if vec is not None:\n",
        "        text_vectors[caption_id] = vec\n"
      ],
      "metadata": {
        "id": "SfMuCZWHO45s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_vectors)\n",
        "\n"
      ],
      "metadata": {
        "id": "PiEPL5gHO_5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(text_vectors.values())).shape\n"
      ],
      "metadata": {
        "id": "UG328yDgPE7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом, текстовые описания были векторизованы с использованием предобученной модели BERT. В результате получены семантические представления фиксированной размерности 768 для 688 уникальных текстовых описаний."
      ],
      "metadata": {
        "id": "U0qGkfHvQ83B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Векторизация изображений**"
      ],
      "metadata": {
        "id": "3J_LEEqWRLpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "image_vectors = {}\n",
        "\n",
        "for img_name in tqdm(clean_df['image_name'].unique()):\n",
        "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        continue\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    vec = model.predict(x, verbose=0)[0]\n",
        "    image_vectors[img_name] = vec\n"
      ],
      "metadata": {
        "id": "Rbg5cKHHV6cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_vectors)\n",
        "image_vectors[next(iter(image_vectors))].shape\n"
      ],
      "metadata": {
        "id": "-Re_1WGSZKMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Векторизация изображений была выполнена с использованием модели ResNet50, предобученной на ImageNet. Для каждого изображения был получен эмбеддинг размерности 2048"
      ],
      "metadata": {
        "id": "GYMgg2L9ZQSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Объединение векторов**"
      ],
      "metadata": {
        "id": "ptVcTumyZUR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "image_names = []\n",
        "skipped = 0\n",
        "\n",
        "for _, row in merged_df.iterrows():\n",
        "    img_name = row['image_name']\n",
        "    caption_id = row['caption_id']\n",
        "    target = row['target']\n",
        "\n",
        "\n",
        "    img_vec = image_vectors.get(img_name)\n",
        "    txt_vec = text_vectors.get(caption_id)\n",
        "\n",
        "    if img_vec is None or txt_vec is None:\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    X.append(np.concatenate([img_vec, txt_vec]))\n",
        "    y.append(target)\n",
        "    image_names.append(img_name)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Пропущено строк:\", skipped)"
      ],
      "metadata": {
        "id": "3CnCUBhGgf54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После объединения визуальных и текстовых эмбеддингов сформирована итоговая обучающая выборка размером 4175 объектов с общей размерностью признакового пространства 2816.\n",
        "1521 объектов были исключены, так как для них отсутствовал либо вектор изображения, либо вектор текста."
      ],
      "metadata": {
        "id": "x5KQTLZFaII3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обучение модели предсказания соответствия**"
      ],
      "metadata": {
        "id": "7AoQub9vbdpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df['image_name'] = image_names\n",
        "\n"
      ],
      "metadata": {
        "id": "MwJjJiF6bjId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df['image_name'] = image_names\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
        "\n",
        "train_idx, val_idx = next(\n",
        "    gss.split(\n",
        "        X=df.drop(columns=['target']),\n",
        "        y=df['target'],\n",
        "        groups=df['image_name']\n",
        "    )\n",
        ")\n",
        "\n",
        "train_df = df.loc[train_idx].reset_index(drop=True)\n",
        "val_df   = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "X_train = train_df.drop(columns=['target', 'image_name']).values\n",
        "y_train = train_df['target'].values\n",
        "\n",
        "X_val = val_df.drop(columns=['target', 'image_name']).values\n",
        "y_val = val_df['target'].values\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val  :\", X_val.shape)\n"
      ],
      "metadata": {
        "id": "BNXIWRhYiauZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled   = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "JSyV6k0HWolN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"alpha\": [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_ridge = grid.best_estimator_\n",
        "\n",
        "y_val_pred_ridge = best_ridge.predict(X_val_scaled)\n",
        "\n",
        "print(\"Best alpha:\", grid.best_params_[\"alpha\"])\n",
        "print(\"Ridge Regression (validation):\")\n",
        "print(\"MSE:\", mean_squared_error(y_val, y_val_pred_ridge))\n",
        "print(\"MAE:\", mean_absolute_error(y_val, y_val_pred_ridge))\n",
        "print(\"R2 :\", r2_score(y_val, y_val_pred_ridge))"
      ],
      "metadata": {
        "id": "V1Ft8FsAWsah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = Sequential([\n",
        "    Dense(1024, input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "nn_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = nn_model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "jpj08VkKW-4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_nn = nn_model.predict(X_val_scaled).ravel()\n",
        "\n",
        "print(\"Neural Network (validation):\")\n",
        "print(\"MSE:\", mean_squared_error(y_val, y_val_pred_nn))\n",
        "print(\"MAE:\", mean_absolute_error(y_val, y_val_pred_nn))\n",
        "print(\"R2 :\", r2_score(y_val, y_val_pred_nn))\n"
      ],
      "metadata": {
        "id": "gQn92mmAXCfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Были обучены и сравнены две модели регрессии: линейная модель с L2-регуляризацией (Ridge Regression) и полносвязная нейронная сеть.\n",
        "\n",
        "Модель Ridge Regression была использована в качестве базовой линейной модели. По результатам валидации модель показала следующие значения метрик:\n",
        "\n",
        "MSE = 0.082\n",
        "\n",
        "MAE = 0.216\n",
        "\n",
        "R² = −0.28\n",
        "\n",
        "\n",
        "\n",
        "Отрицательное значение коэффициента детерминации указывает на то, что линейная модель не способна адекватно описать зависимость между эмбеддингами изображений и текстов и целевой экспертной оценкой. Фактически модель работает хуже, чем предсказание среднего значения.\n",
        "\n",
        "Полносвязная нейронная сеть была обучена для моделирования нелинейных зависимостей между признаками. Использование нескольких скрытых слоёв, нормализации и регуляризации позволило модели учитывать сложные взаимодействия между визуальными и текстовыми представлениями.\n",
        "\n",
        "По результатам валидации нейронная сеть показала лучшие результаты:\n",
        "\n",
        "MSE = 0.049\n",
        "\n",
        "MAE = 0.152\n",
        "\n",
        "R² = 0.22\n",
        "\n",
        "По сравнению с линейной моделью наблюдается:\n",
        "снижение MSE, уменьшение MAE.\n",
        "\n",
        "Полносвязная нейронная сеть  превосходит линейную модель и является предпочтительным решением для данной задачи."
      ],
      "metadata": {
        "id": "xHL-_yvEa2Te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Тестирование модели и демонстрация ее работы**"
      ],
      "metadata": {
        "id": "L2lnTkQ5bwfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def contains_blocked_words(text: str) -> bool:\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "\n",
        "    text = text.lower()\n",
        "    tokens = re.findall(r\"\\b\\w+\\b\", text)\n",
        "\n",
        "    return any(token in BLOCK_LEMMAS for token in tokens)"
      ],
      "metadata": {
        "id": "8DAOGFhfKEAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_vector(text, max_length=64):\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    vector = outputs.last_hidden_state.mean(dim=1)\n",
        "    return vector.squeeze().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "elgHALoTiWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_images(\n",
        "    text: str,\n",
        "    model,\n",
        "    image_vectors: dict,\n",
        "    top_n: int = 10\n",
        "):\n",
        "\n",
        "    if contains_blocked_words(text):\n",
        "        return [(\"⚠️ Disclaimer: request may involve sensitive content.\", None)]\n",
        "\n",
        "\n",
        "    text_vec = text_to_vector(text)\n",
        "    if text_vec is None:\n",
        "        return []\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for img_name, img_vec in image_vectors.items():\n",
        "        x = np.concatenate([img_vec, text_vec]).reshape(1, -1)\n",
        "        score = model.predict(x, verbose=0)[0][0]\n",
        "        scores.append((img_name, float(score)))\n",
        "\n",
        "\n",
        "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    return scores[:top_n]\n"
      ],
      "metadata": {
        "id": "ooKqaJE5iZ6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images_grid(image_names, images_dir=IMAGES_DIR, cols=5):\n",
        "    rows = (len(image_names) + cols - 1) // cols\n",
        "    plt.figure(figsize=(4 * cols, 4 * rows))\n",
        "\n",
        "    for i, img_name in enumerate(image_names):\n",
        "        img_path = os.path.join(images_dir, img_name)\n",
        "        if os.path.exists(img_path):\n",
        "            img = PILImage.open(img_path).convert(\"RGB\")\n",
        "            plt.subplot(rows, cols, i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(img_name, fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zx3VURlsic0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"child playing in sandbox\",\n",
        "    \"kids painting on paper\",\n",
        "    \"happy child with toy\",\n",
        "    \"dog running in park\",\n",
        "    \"people walking in the city\"\n",
        "]\n",
        "\n",
        "top_n = 10\n",
        "\n",
        "for q in queries:\n",
        "    print(f\"Query: {q}\")\n",
        "\n",
        "    results = find_top_images(\n",
        "        text=q,\n",
        "        model=nn_model,\n",
        "        image_vectors=image_vectors,\n",
        "        top_n=top_n\n",
        "    )\n",
        "\n",
        "    image_names = []\n",
        "\n",
        "    for img_name, score in results:\n",
        "        if img_name is None or \"Disclaimer\" in str(img_name):\n",
        "            print(img_name)\n",
        "        else:\n",
        "            print(f\"Image: {img_name}, Score: {score:.3f}\")\n",
        "            image_names.append(img_name)\n",
        "\n",
        "    if image_names:\n",
        "        show_images_grid(image_names, cols=5)\n",
        "\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "id": "oWbHsTMkihP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что модель склонна выдавать ограниченный набор изображений. Модель способна выявлять общее соответствие между текстовыми описаниями и изображениями и корректно выделяет часть релевантных изображений в верхних позициях выдачи. При этом наблюдается слабая дифференциация результатов для разных запросов: наборы топ-изображений во многом пересекаются, а различия в оценках невелики. Это свидетельствует о том, что модель улавливает лишь грубую семантическую близость и недостаточно чувствительна к деталям текстового запроса."
      ],
      "metadata": {
        "id": "XZSOU5IXnrpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**"
      ],
      "metadata": {
        "id": "cKDyTxsTuF3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Подготовка данных\n",
        "Был сформирован единый датасет, содержащий:\n",
        "\n",
        "векторные представления изображений,\n",
        "\n",
        "текстовые описания,\n",
        "\n",
        "целевую метрику сходства «картинка–текст».\n",
        "Для корректной оценки качества данные были разделены на обучающую, валидационную и тестовую выборки с учетом группировки по изображениям, что позволило избежать утечки данных.\n",
        "\n",
        "- Векторизация текста\n",
        "Для преобразования текстовых запросов в числовые признаки использовалась модель BERT. Текст переводился в эмбеддинг фиксированной размерности путем усреднения скрытых состояний, что позволило получить семантически осмысленное представление запросов.\n",
        "\n",
        "- Использование визуальных признаков\n",
        "Для изображений применялись заранее полученные векторные представления, отражающие визуальное содержание картинок. Это позволило работать с изображениями в числовом виде без обучения сверточной сети с нуля.\n",
        "\n",
        "- Построение моделей\n",
        "Были реализованы и сравнены несколько подходов:\n",
        "\n",
        "линейная регрессия и ridge-регрессия как базовые модели,\n",
        "\n",
        "полносвязная нейронная сеть, способная учитывать нелинейные зависимости между текстовыми и визуальными признаками.\n",
        "\n",
        "- Оценка качества моделей\n",
        "Качество моделей оценивалось с помощью метрик MSE, MAE и R² на валидационной выборке. Нейронная сеть показала лучшие результаты по всем ключевым метрикам по сравнению с линейными моделями.\n",
        "\n",
        "Лучшие результаты показала полносвязная нейронная сеть, обученная на  векторах изображения и текста. По сравнению с линейной и ridge-регрессией, нейросетевая модель продемонстрировала более низкие значения MSE и MAE, а также положительное значение коэффициента детерминации, что указывает на способность модели улавливать нелинейные зависимости между визуальными и текстовыми признаками.\n",
        "\n",
        "Во время поиска изображений по текстовому запросу модель допускает ряд  ошибок. Во-первых, она часто выдает схожие наборы изображений для разных, но семантически близких запросов, что говорит о слабой чувствительности к деталям текста.\n",
        "\n",
        "Во-вторых, в топ-результатах нередко присутствуют изображения, соответствующие лишь общей сцене или контексту, но не ключевым объектам запроса. Кроме того, оценки сходства между изображениями часто отличаются незначительно.\n",
        "\n",
        "В целом проект по созданию сервиса поиска фотографий по текстовому описанию  осуществим: даже базовая архитектура демонстрирует способность находить релевантные изображения и корректно ранжировать часть результатов. Однако для использования в реальных условиях требуется дальнейшее улучшение качества."
      ],
      "metadata": {
        "id": "w8lBd1sFuLNL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}